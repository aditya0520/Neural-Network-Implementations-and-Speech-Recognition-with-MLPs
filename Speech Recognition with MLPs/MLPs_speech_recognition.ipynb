{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ERgBpbcMmB"
      },
      "source": [
        "# HW1: Frame-Level Speech Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLkH6GMGcWcE"
      },
      "source": [
        "In this homework, you will be working with MFCC data consisting of 28 features at each time step/frame. Your model should be able to recognize the phoneme occured in that frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vZbDmJvMp1"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwYu9sSUnSho"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummaryX==1.1.0 wandb --quiet\n",
        "!pip install torch-optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI4qfx7tiBZt",
        "outputId": "83aa72d1-4e82-428c-a534-ccee82bc3be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import datetime\n",
        "import numpy as np\n",
        "from torchsummaryX import summary\n",
        "import sklearn\n",
        "import random\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import torch_optimizer as optimx\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import os\n",
        "import datetime\n",
        "import wandb\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "scaler = GradScaler()\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yBgXjKV1O0Z"
      },
      "outputs": [],
      "source": [
        "''' If you are using colab, you can import google drive to save model checkpoints in a folder\n",
        "    If you want to use it, uncomment the two lines below\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FTIoCMtMuEUz",
        "outputId": "75ae919c-a031-43b5-9cf9-4f3751c6a496"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N-9qE20hmCgQ"
      },
      "outputs": [],
      "source": [
        "### PHONEME LIST\n",
        "PHONEMES = [\n",
        "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',\n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIi0Big7vPa9"
      },
      "source": [
        "# Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBCbeRhixGM7"
      },
      "source": [
        "This section contains code that helps you install kaggle's API, creating kaggle.json with you username and API key details. Make sure to input those in the given code to ensure you can download data from the competition successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPBUd7Cnl-Rx",
        "outputId": "c45cbd46-0c00-4377-9c3a-a4812abb2e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Using cached kaggle-1.5.8-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.8\n",
            "    Uninstalling kaggle-1.5.8:\n",
            "      Successfully uninstalled kaggle-1.5.8\n",
            "Successfully installed kaggle-1.5.8\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"aaayush1\",\"key\":\"9ad570c944c8b67cf242fb16c7cf3f40\"}')\n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if2Somqfbje1",
        "outputId": "009fab4e-6618-4837-a0cd-a804172d84d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 11785-hw1p2-f24.zip to /content\n",
            "100% 3.98G/3.98G [00:16<00:00, 264MB/s]\n",
            "100% 3.98G/3.98G [00:16<00:00, 258MB/s]\n"
          ]
        }
      ],
      "source": [
        "# commands to download data from kaggle\n",
        "!kaggle competitions download -c 11785-hw1p2-f24\n",
        "\n",
        "!unzip -qo /content/11785-hw1p2-f24.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuzce0_TdcaR"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_7QgMbBdgPp"
      },
      "source": [
        "This section covers the dataset/dataloader class for speech data. You will have to spend time writing code to create this class successfully. We have given you a lot of comments guiding you on what code to write at each stage, from top to bottom of the class. Please try and take your time figuring this out, as it will immensely help in creating dataset/dataloader classes for future homeworks.\n",
        "\n",
        "Before running the following cells, please take some time to analyse the structure of data. Try loading a single MFCC and its transcipt, print out the shapes and print out the values. Do the transcripts look like phonemes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCSPb-NDGw6s",
        "outputId": "44db00c9-9654-468e-c99b-5f9a83122b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(477, 28)\n",
            "[[ 1.70536385e+01  1.83756161e+01  1.32918272e+01 ... -1.50571261e-02\n",
            "  -6.27577156e-02  7.39348907e+01]\n",
            " [ 1.71380692e+01  1.84768028e+01  1.27026825e+01 ...  2.04224527e-01\n",
            "  -1.66671127e-01  7.42002716e+01]\n",
            " [ 1.77663155e+01  1.70868053e+01  1.09276438e+01 ...  9.05482650e-01\n",
            "  -9.12217647e-02  7.37023163e+01]\n",
            " ...\n",
            " [ 1.73955116e+01  4.50241947e+00  5.95822906e+00 ...  7.46107638e-01\n",
            "   2.80462001e-02  7.80584183e+01]\n",
            " [ 1.65330410e+01  3.57640982e+00  4.13166904e+00 ... -5.02605319e-01\n",
            "  -2.23344006e-02  7.97978287e+01]\n",
            " [ 1.45076504e+01  2.15292788e+00  6.49814081e+00 ... -4.83489990e-01\n",
            "  -4.38078865e-02  8.09142075e+01]]\n",
            "(479,)\n",
            "['[SOS]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'AO' 'AO' 'AO' 'AO' 'AO' 'AO' 'R' 'R' 'R'\n",
            " 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'IH' 'IH' 'IH'\n",
            " 'IH' 'IH' 'IH' 'IH' 'IH' 'IH' 'IH' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z'\n",
            " 'Z' 'Z' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'IH' 'IH' 'IH' 'IH' 'S' 'S' 'S'\n",
            " 'S' 'S' 'T' 'T' 'T' 'T' 'T' 'T' 'T' 'ER' 'ER' 'ER' 'ER' 'K' 'K' 'K' 'K'\n",
            " 'K' 'K' 'K' 'K' 'W' 'W' 'W' 'W' 'IH' 'IH' 'IH' 'L' 'L' 'L' 'L' 'L' 'L'\n",
            " 'L' 'L' 'T' 'T' 'T' 'T' 'T' 'T' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER'\n",
            " 'ER' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER'\n",
            " 'ER' 'ER' 'ER' 'ER' 'ER' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L'\n",
            " 'EH' 'EH' 'EH' 'EH' 'EH' 'EH' 'EH' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n",
            " 'S' 'S' 'S' 'S' 'S' 'S' 'IH' 'IH' 'IH' 'IH' 'IH' 'IH' 'IH' 'IH' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'T' 'T' 'T' 'T' 'T' 'T' 'T' 'T' 'T' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'AH' 'S' 'S'\n",
            " 'S' 'S' 'S' 'T' 'T' 'T' 'T' 'T' 'T' 'IH' 'IH' 'IH' 'NG' 'NG' 'NG' 'NG'\n",
            " 'NG' 'NG' 'NG' 'NG' 'NG' 'NG' 'DH' 'DH' 'DH' 'DH' 'DH' 'DH' 'DH' 'DH'\n",
            " 'DH' 'DH' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'N' 'N' 'N' 'N' 'N'\n",
            " 'HH' 'HH' 'HH' 'HH' 'HH' 'HH' 'HH' 'HH' 'HH' 'HH' 'HH' 'IH' 'IH' 'IH'\n",
            " 'IH' 'IH' 'IH' 'IH' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z' 'Z'\n",
            " 'Z' 'Z' 'Z' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'AE' 'T' 'T' 'T' 'T'\n",
            " 'T' 'T' 'T' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER'\n",
            " 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' 'ER' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]'\n",
            " '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[SIL]' '[EOS]']\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/11785-f24-hw1p2/dev-clean/mfcc/1272-128104-0001.npy'\n",
        "\n",
        "# Load the .npy file\n",
        "data = np.load(file_path)\n",
        "\n",
        "# Print the contents\n",
        "print(data.shape)\n",
        "print(data)\n",
        "\n",
        "\n",
        "file_path = '/content/11785-f24-hw1p2/dev-clean/transcript/1272-128104-0001.npy'\n",
        "\n",
        "# Load the .npy file\n",
        "data = np.load(file_path)\n",
        "\n",
        "# Print the contents\n",
        "print(data.shape)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIFRfMCAfH0G",
        "outputId": "22dff309-05ed-467b-a10c-ddba18212908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1264.6258453344547\n",
            "137\n",
            "2448\n"
          ]
        }
      ],
      "source": [
        "mfcc_dir = os.path.join('/content/11785-f24-hw1p2', 'train-clean-100', \"mfcc\")\n",
        "# TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "\n",
        "# TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
        "mfcc_names          = sorted(os.listdir(mfcc_dir))\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Iterate through mfccs and transcripts\n",
        "mfcc_lengths = []\n",
        "\n",
        "# Iterate through MFCC files\n",
        "for i in range(len(mfcc_names)):\n",
        "    mfcc_path = os.path.join(mfcc_dir, mfcc_names[i])\n",
        "\n",
        "    # Load the MFCC\n",
        "    mfcc = np.load(mfcc_path)\n",
        "\n",
        "    # Append the number of time steps (shape[0]) to the list\n",
        "    mfcc_lengths.append(mfcc.shape[0])\n",
        "\n",
        "# Calculate the mean, min, and max\n",
        "mean_length = np.mean(mfcc_lengths)\n",
        "min_length = np.min(mfcc_lengths)\n",
        "max_length = np.max(mfcc_lengths)\n",
        "\n",
        "print(mean_length)\n",
        "print(min_length)\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YpLCvi3AJC5z"
      },
      "outputs": [],
      "source": [
        "# Dataset class to load train and validation data\n",
        "\n",
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"train-clean-100\", training = True): # Feel free to add more arguments\n",
        "\n",
        "        self.context    = context\n",
        "        self.phonemes   = phonemes\n",
        "        self.training   = training\n",
        "\n",
        "        # TODO: MFCC directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        self.mfcc_dir = os.path.join(root, partition, \"mfcc\")\n",
        "        # TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        self.transcript_dir = os.path.join(root, partition, \"transcript\")\n",
        "\n",
        "        # TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
        "        mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "        # TODO: List files in self.transcript_dir using os.listdir in sorted order\n",
        "        transcript_names    = sorted(os.listdir(self.transcript_dir))\n",
        "\n",
        "        # Making sure that we have the same no. of mfcc and transcripts\n",
        "        assert len(mfcc_names) == len(transcript_names)\n",
        "\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "        # TODO: Iterate through mfccs and transcripts\n",
        "        for i in range(len(mfcc_names)):\n",
        "            mfcc_path = os.path.join(self.mfcc_dir, mfcc_names[i])\n",
        "            transcript_path = os.path.join(self.transcript_dir, transcript_names[i])\n",
        "        #   Load a single mfcc\n",
        "            mfcc        = np.load(mfcc_path)\n",
        "        #   Do Cepstral Normalization of mfcc (explained in writeup)\n",
        "\n",
        "            mfcc = mfcc - np.mean(mfcc, axis=0, keepdims=True)\n",
        "            mfcc = mfcc / np.std(mfcc, axis=0, keepdims=True)\n",
        "\n",
        "        #   Load the corresponding transcript\n",
        "            transcript  = np.load(transcript_path)[1:-1] # Remove [SOS] and [EOS] from the transcript\n",
        "            # (Is there an efficient way to do this without traversing through the transcript?)\n",
        "            # Note that SOS will always be in the starting and EOS at end, as the name suggests.\n",
        "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)\n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 28, T2 x 28, ...\n",
        "        # Each transcript is of shape (T1+2), (T2+2) before removing [SOS] and [EOS]\n",
        "\n",
        "        # TODO: Concatenate all mfccs in self.mfccs such that\n",
        "        # the final shape is T x 28 (Where T = T1 + T2 + ...)\n",
        "        self.mfccs          = np.concatenate(self.mfccs, axis=0)\n",
        "\n",
        "        # TODO: Concatenate all transcripts in self.transcripts such that\n",
        "        # the final shape is (T,) meaning, each time step has one phoneme output\n",
        "        self.transcripts    = np.concatenate(self.transcripts, axis=0)\n",
        "        # Hint: Use numpy to concatenate\n",
        "\n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "        # Take some time to think about what we have done.\n",
        "        # self.mfcc is an array of the format (Frames x Features).\n",
        "        # Our goal is to recognize phonemes of each frame\n",
        "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
        "        padding = np.zeros((self.context, self.mfccs.shape[1]))\n",
        "        self.mfccs = np.vstack([padding, self.mfccs, padding])\n",
        "\n",
        "        # The available phonemes in the transcript are of string data type\n",
        "        # But the neural network cannot predict strings as such.\n",
        "        # Hence, we map these phonemes to integers\n",
        "\n",
        "        # TODO: Map the phonemes to their corresponding list indexes in self.phonemes\n",
        "        self.phoneme_to_int = {phoneme : i for i, phoneme in enumerate(self.phonemes)}\n",
        "        self.transcripts = np.array([self.phoneme_to_int[phoneme] for phoneme in self.transcripts])\n",
        "        # Now, if an element in self.transcript is 0, it means that it is 'SIL' (as per the above example)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def time_mask(self, mfcc, time_mask_fraction):\n",
        "            \"\"\"\n",
        "            Apply time masking with a fraction of total frames.\n",
        "            time_mask_fraction: Fraction of frames to mask (between 0 and 1).\n",
        "            \"\"\"\n",
        "            t = mfcc.shape[0]\n",
        "            max_time_mask = int(t * time_mask_fraction)\n",
        "            if max_time_mask == 0:\n",
        "                return mfcc\n",
        "\n",
        "            # Choose a random mask length between 1 and max_time_mask\n",
        "            time_mask_param = random.randint(0, max_time_mask)\n",
        "            t0 = random.randint(0, t - time_mask_param)\n",
        "            mfcc[t0:t0 + time_mask_param, :] = 0\n",
        "            return mfcc\n",
        "\n",
        "\n",
        "    def frequency_mask(self, mfcc, freq_mask_fraction):\n",
        "        \"\"\"\n",
        "        Apply frequency masking with a fraction of total coefficients.\n",
        "        freq_mask_fraction: Fraction of frequency bins to mask (between 0 and 1).\n",
        "        \"\"\"\n",
        "        f = mfcc.shape[1]\n",
        "        max_freq_mask = int(f * freq_mask_fraction)\n",
        "        if max_freq_mask == 0:\n",
        "            return mfcc\n",
        "\n",
        "        # Choose a random mask length between 1 and max_freq_mask\n",
        "        freq_mask_param = random.randint(0, max_freq_mask)\n",
        "        f0 = random.randint(0, f - freq_mask_param)\n",
        "        mfcc[:, f0:f0 + freq_mask_param] = 0\n",
        "        return mfcc\n",
        "\n",
        "    def apply_spec_augment(self, mfcc, time_mask_fraction, freq_mask_fraction):\n",
        "        \"\"\"\n",
        "        Apply both time and frequency masking using fractions.\n",
        "        \"\"\"\n",
        "        mfcc = self.time_mask(mfcc, time_mask_fraction)\n",
        "        mfcc = self.frequency_mask(mfcc, freq_mask_fraction)\n",
        "        return mfcc\n",
        "\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "\n",
        "        # TODO: Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
        "        start_index = ind\n",
        "        end_index = ind + 2 * self.context + 1\n",
        "        frames = self.mfccs[start_index: end_index, :]\n",
        "\n",
        "        if self.training:\n",
        "          if random.random() <= 0.15:\n",
        "            for i in range(2):\n",
        "              frames = self.apply_spec_augment(frames, time_mask_fraction=0.04, freq_mask_fraction=0.05)\n",
        "\n",
        "\n",
        "        # After slicing, you get an array of shape 2*context+1 x 28. But our MLP needs 1d data and not 2d.\n",
        "        frames = frames.flatten() # TODO: Flatten to get 1d data\n",
        "\n",
        "        frames      = torch.FloatTensor(frames) # Convert to tensors\n",
        "        phonemes    = torch.tensor(self.transcripts[ind])\n",
        "\n",
        "        return frames, phonemes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e8KfVP39S6o7"
      },
      "outputs": [],
      "source": [
        "class AudioTestDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, root, context=0, partition= \"test-clean\"): # Feel free to add more arguments\n",
        "\n",
        "          self.context    = context\n",
        "          self.mfcc_dir = os.path.join(root, partition, \"mfcc\")\n",
        "          mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "\n",
        "          self.mfccs = []\n",
        "          for i in range(len(mfcc_names)):\n",
        "              mfcc_path = os.path.join(self.mfcc_dir, mfcc_names[i])\n",
        "              mfcc        = np.load(mfcc_path)\n",
        "              mfcc = mfcc - np.mean(mfcc, axis=0, keepdims=True)\n",
        "              mfcc = mfcc / np.std(mfcc, axis=0, keepdims=True)\n",
        "              self.mfccs.append(mfcc)\n",
        "\n",
        "          self.mfccs          = np.concatenate(self.mfccs, axis=0)\n",
        "          self.length = len(self.mfccs)\n",
        "          padding = np.zeros((self.context, self.mfccs.shape[1]))\n",
        "          self.mfccs = np.vstack([padding, self.mfccs, padding])\n",
        "\n",
        "        def __len__(self):\n",
        "          return self.length\n",
        "\n",
        "        def __getitem__(self, ind):\n",
        "\n",
        "            start_index = ind\n",
        "            end_index = ind + 2 * self.context + 1\n",
        "            frames = self.mfccs[start_index: end_index, :]\n",
        "            frames = frames.flatten()\n",
        "            frames      = torch.FloatTensor(frames)\n",
        "\n",
        "            return frames\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Create a test dataset class similar to the previous class but you dont have transcripts for this\n",
        "    # Imp: Read the mfccs in sorted order, do NOT shuffle the data here or in your dataloader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNacQ8bpt9nw"
      },
      "source": [
        "# Parameters Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7tsinAuLNy"
      },
      "source": [
        "Storing your parameters and hyperparameters in a single configuration dictionary makes it easier to keep track of them during each experiment. It can also be used with weights and biases to log your parameters for each experiment and keep track of them across multiple experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PmKwlFqgt_Zq"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'epochs'        : 104,\n",
        "    'batch_size'    : 2048,\n",
        "    'context'       : 35,\n",
        "    'init_lr'       : 1e-3,\n",
        "    'architecture'  : '15th-iteration',\n",
        "    'scheduler_type'    : 'CosineAnnealingRestart',\n",
        "    'first_restart' : 4,\n",
        "    'period_multipler' : 2,\n",
        "    'decay_factor' : 0.7\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mlwaKlDt_2c"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7xi7V8x8W9z4"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/11785-f24-hw1p2'\n",
        "#TODO: Create a dataset object using the AudioDataset class for the training data\n",
        "train_data = AudioDataset(root=root_dir, partition=\"train-clean-100\", context=config['context'], training = True)\n",
        "\n",
        "# TODO: Create a dataset object using the AudioDataset class for the validation data\n",
        "val_data = AudioDataset(root=root_dir, partition=\"dev-clean\", context=config['context'], training = False)\n",
        "\n",
        "# TODO: Create a dataset object using the AudioTestDataset class for the test data\n",
        "test_data = AudioTestDataset(root=root_dir, partition= \"test-clean\", context=config['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzoYfTKu14s",
        "outputId": "3ca07a56-b012-432f-caa3-dcc2babc85c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size     :  2048\n",
            "Context        :  35\n",
            "Input size     :  1988\n",
            "Output symbols :  42\n",
            "Train dataset samples = 36091157, batches = 17623\n",
            "Validation dataset samples = 1928204, batches = 942\n",
            "Test dataset samples = 1934138, batches = 945\n"
          ]
        }
      ],
      "source": [
        "# Define dataloaders for train, val and test datasets\n",
        "# Dataloaders will yield a batch of frames and phonemes of given batch_size at every iteration\n",
        "# We shuffle train dataloader but not val & test dataloader. Why?\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data,\n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data,\n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data,\n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Batch size     : \", config['batch_size'])\n",
        "print(\"Context        : \", config['context'])\n",
        "print(\"Input size     : \", (2*config['context']+1)*28)\n",
        "print(\"Output symbols : \", len(PHONEMES))\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GV3UvgLSoF",
        "outputId": "f7118934-a3ae-422e-ae1b-2f574a515c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2048, 1988]) torch.Size([2048])\n"
          ]
        }
      ],
      "source": [
        "# Testing code to check if your data loaders are working\n",
        "for i, data in enumerate(train_loader):\n",
        "    frames, phoneme = data\n",
        "    print(frames.shape, phoneme.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_et2NhWFkJ5",
        "outputId": "4e549d36-e77c-406f-b62f-cca2003ea45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SIL in dev  319908\n"
          ]
        }
      ],
      "source": [
        "sil_count = 0\n",
        "# Testing code to check if your data loaders are working\n",
        "for i, data in enumerate(val_loader):\n",
        "    frames, phoneme = data\n",
        "    sil_count += (phoneme == 0).sum().item()\n",
        "\n",
        "print(\"SIL in dev \", sil_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTQ0Q9xzGbjJ",
        "outputId": "fadc20bd-6755-4d57-be8f-def4ca18d701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phoneme: 0, Count: 319908\n",
            "Phoneme: 22, Count: 44728\n",
            "Phoneme: 17, Count: 74887\n",
            "Phoneme: 29, Count: 101184\n",
            "Phoneme: 31, Count: 97390\n",
            "Phoneme: 12, Count: 54928\n",
            "Phoneme: 20, Count: 47016\n",
            "Phoneme: 36, Count: 37697\n",
            "Phoneme: 21, Count: 65902\n",
            "Phoneme: 38, Count: 54850\n",
            "Phoneme: 10, Count: 37100\n",
            "Phoneme: 3, Count: 123734\n",
            "Phoneme: 27, Count: 34131\n",
            "Phoneme: 1, Count: 29688\n",
            "Phoneme: 35, Count: 27440\n",
            "Phoneme: 9, Count: 62763\n",
            "Phoneme: 2, Count: 49298\n",
            "Phoneme: 23, Count: 94541\n",
            "Phoneme: 18, Count: 70861\n",
            "Phoneme: 28, Count: 62686\n",
            "Phoneme: 15, Count: 13541\n",
            "Phoneme: 34, Count: 26691\n",
            "Phoneme: 11, Count: 47112\n",
            "Phoneme: 16, Count: 34813\n",
            "Phoneme: 4, Count: 29340\n",
            "Phoneme: 24, Count: 19327\n",
            "Phoneme: 14, Count: 37562\n",
            "Phoneme: 37, Count: 9669\n",
            "Phoneme: 25, Count: 30755\n",
            "Phoneme: 7, Count: 23607\n",
            "Phoneme: 6, Count: 49332\n",
            "Phoneme: 13, Count: 36184\n",
            "Phoneme: 5, Count: 20274\n",
            "Phoneme: 32, Count: 9247\n",
            "Phoneme: 8, Count: 12644\n",
            "Phoneme: 30, Count: 17628\n",
            "Phoneme: 19, Count: 8730\n",
            "Phoneme: 26, Count: 3861\n",
            "Phoneme: 39, Count: 869\n",
            "Phoneme: 33, Count: 6286\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "phoneme_counts = defaultdict(int)\n",
        "\n",
        "for i, data in enumerate(val_loader):\n",
        "    frames, phoneme = data\n",
        "\n",
        "    for p in phoneme:\n",
        "        phoneme_counts[p.item()] += 1\n",
        "\n",
        "\n",
        "for phoneme, count in phoneme_counts.items():\n",
        "    print(f\"Phoneme: {phoneme}, Count: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnYXFxl5HGvw",
        "outputId": "29aa9458-fa55-4ecc-db4a-291c9d248c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "least_frequent_phoneme = min(phoneme_counts, key=phoneme_counts.get)\n",
        "least_frequent_count = phoneme_counts[least_frequent_phoneme]\n",
        "print(least_frequent_phoneme)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cff42bZgGz11",
        "outputId": "4d2da270-4c5d-4373-f14b-0667f0f57940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'[SIL]': 0, 'AA': 1, 'AE': 2, 'AH': 3, 'AO': 4, 'AW': 5, 'AY': 6, 'B': 7, 'CH': 8, 'D': 9, 'DH': 10, 'EH': 11, 'ER': 12, 'EY': 13, 'F': 14, 'G': 15, 'HH': 16, 'IH': 17, 'IY': 18, 'JH': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'NG': 24, 'OW': 25, 'OY': 26, 'P': 27, 'R': 28, 'S': 29, 'SH': 30, 'T': 31, 'TH': 32, 'UH': 33, 'UW': 34, 'V': 35, 'W': 36, 'Y': 37, 'Z': 38, 'ZH': 39, '[SOS]': 40, '[EOS]': 41}\n"
          ]
        }
      ],
      "source": [
        "print(val_data.phoneme_to_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxjwve20JRJ2"
      },
      "source": [
        "# Network Architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJzT-mRw6iy"
      },
      "source": [
        "This section defines your network architecture for the homework. We have given you a sample architecture that can easily clear the very low cutoff for the early submission deadline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IY2r_NlzVN1x"
      },
      "outputs": [],
      "source": [
        "class Network(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 1995),\n",
        "            torch.nn.BatchNorm1d(1995),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.17),\n",
        "\n",
        "            #Hidden Layers - Start\n",
        "            torch.nn.Linear(1995, 1995),\n",
        "            torch.nn.BatchNorm1d(1995),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.20),\n",
        "\n",
        "            torch.nn.Linear(1995, 1995),\n",
        "            torch.nn.BatchNorm1d(1995),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.25),\n",
        "\n",
        "            torch.nn.Linear(1995, 1995),\n",
        "            torch.nn.BatchNorm1d(1995),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.20),\n",
        "\n",
        "            torch.nn.Linear(1995, 1995),\n",
        "            torch.nn.BatchNorm1d(1995),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.17),\n",
        "            #Hidden Layers - End\n",
        "\n",
        "            # Final output layer\n",
        "            torch.nn.Linear(1995, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejoSXe3vMVU"
      },
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhGBH7-xxth"
      },
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qtrEM1ZvLje",
        "outputId": "8a44a4f6-e001-426c-b5f5-e19bfbe5e48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Layer                   Kernel Shape         Output Shape         # Params (K)      # Mult-Adds (M)\n",
            "====================================================================================================\n",
            "0_Linear                [1988, 1995]         [2048, 1995]             3,968.05                 3.97\n",
            "1_BatchNorm1d                 [1995]         [2048, 1995]                 3.99                 0.00\n",
            "2_ReLU                             -         [2048, 1995]                    -                    -\n",
            "3_Dropout                          -         [2048, 1995]                    -                    -\n",
            "4_Linear                [1995, 1995]         [2048, 1995]             3,982.02                 3.98\n",
            "5_BatchNorm1d                 [1995]         [2048, 1995]                 3.99                 0.00\n",
            "6_ReLU                             -         [2048, 1995]                    -                    -\n",
            "7_Dropout                          -         [2048, 1995]                    -                    -\n",
            "8_Linear                [1995, 1995]         [2048, 1995]             3,982.02                 3.98\n",
            "9_BatchNorm1d                 [1995]         [2048, 1995]                 3.99                 0.00\n",
            "10_ReLU                            -         [2048, 1995]                    -                    -\n",
            "11_Dropout                         -         [2048, 1995]                    -                    -\n",
            "12_Linear               [1995, 1995]         [2048, 1995]             3,982.02                 3.98\n",
            "13_BatchNorm1d                [1995]         [2048, 1995]                 3.99                 0.00\n",
            "14_ReLU                            -         [2048, 1995]                    -                    -\n",
            "15_Dropout                         -         [2048, 1995]                    -                    -\n",
            "16_Linear               [1995, 1995]         [2048, 1995]             3,982.02                 3.98\n",
            "17_BatchNorm1d                [1995]         [2048, 1995]                 3.99                 0.00\n",
            "18_ReLU                            -         [2048, 1995]                    -                    -\n",
            "19_Dropout                         -         [2048, 1995]                    -                    -\n",
            "20_Linear                 [1995, 42]           [2048, 42]                83.83                 0.08\n",
            "====================================================================================================\n",
            "# Params:    19,999.92K\n",
            "# Mult-Adds: 19.98M\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "INPUT_SIZE  = (2*config['context'] + 1) * 28 # Why is this the case?\n",
        "model       = Network(INPUT_SIZE, len(train_data.phonemes)).to(device)\n",
        "summary(model, frames.to(device))\n",
        "# Check number of parameters of your network\n",
        "# Remember, you are limited to 20 million parameters for HW1 (including ensembles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UROGEVJevKD-"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss() # Defining Loss function.\n",
        "# We use CE because the task is multi-class classification\n",
        "\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=config['init_lr'], weight_decay=1e-4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config['init_lr'])\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=7, T_mult=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Recommended : Define Scheduler for Learning Rate,\n",
        "# including but not limited to StepLR, MultiStep, CosineAnnealing, CosineAnnealingWithWarmRestarts, ReduceLROnPlateau, etc.\n",
        "# You can refer to Pytorch documentation for more information on how to use them.\n",
        "\n",
        "# Is your training time very high?\n",
        "# Look into mixed precision training if your GPU (Tesla T4, V100, etc) can make use of it\n",
        "# Refer - https://pytorch.org/docs/stable/notes/amp_examples.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training and Validation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JgeNhx4x2-P"
      },
      "source": [
        "This section covers the training, and validation functions for each epoch of running your experiment with a given model architecture. The code has been provided to you, but we recommend going through the comments to understand the workflow to enable you to write these loops for future HWs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XblOHEVtKab2",
        "outputId": "3858658d-92dc-4538-92e0-19c8b80ca6ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "873"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8wjPz7DHqKcL"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    tloss, tacc = 0, 0  # Monitoring loss and accuracy\n",
        "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "\n",
        "    for i, (frames, phonemes) in enumerate(dataloader):\n",
        "        ### Initialize Gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ### Move Data to Device (Ideally GPU)\n",
        "        frames = frames.to(device)\n",
        "        phonemes = phonemes.to(device)\n",
        "\n",
        "        ### Mixed precision forward pass\n",
        "        with autocast():\n",
        "            logits = model(frames)\n",
        "            loss = criterion(logits, phonemes)\n",
        "\n",
        "        ### Backward pass and gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        ### Gradient Descent step (unscale before stepping optimizer)\n",
        "        scaler.step(optimizer)\n",
        "\n",
        "        ### Update the scaler\n",
        "        scaler.update()\n",
        "\n",
        "        tloss += loss.item()\n",
        "        tacc += torch.sum(torch.argmax(logits, dim=1) == phonemes).item() / logits.shape[0]\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(tloss / (i + 1))),\n",
        "                              acc=\"{:.04f}%\".format(float(tacc * 100 / (i + 1))))\n",
        "        batch_bar.update()\n",
        "\n",
        "        ### Release memory\n",
        "        del frames, phonemes, logits\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    tloss /= len(dataloader)\n",
        "    tacc /= len(dataloader)\n",
        "\n",
        "    return tloss, tacc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q5npQNFH315V"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader):\n",
        "\n",
        "    model.eval() # set model in evaluation mode\n",
        "    vloss, vacc = 0, 0 # Monitoring loss and accuracy\n",
        "    batch_bar   = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    for i, (frames, phonemes) in enumerate(dataloader):\n",
        "\n",
        "        ### Move data to device (ideally GPU)\n",
        "        frames      = frames.to(device)\n",
        "        phonemes    = phonemes.to(device)\n",
        "\n",
        "        # makes sure that there are no gradients computed as we are not training the model now\n",
        "        with torch.inference_mode():\n",
        "            ### Forward Propagation\n",
        "            logits  = model(frames)\n",
        "            ### Loss Calculation\n",
        "            loss    = criterion(logits, phonemes)\n",
        "\n",
        "        vloss   += loss.item()\n",
        "        vacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
        "\n",
        "        # Do you think we need loss.backward() and optimizer.step() here?\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n",
        "                              acc=\"{:.04f}%\".format(float(vacc*100 / (i + 1))))\n",
        "        batch_bar.update()\n",
        "\n",
        "        ### Release memory\n",
        "        del frames, phonemes, logits\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    vloss   /= len(val_loader)\n",
        "    vacc    /= len(val_loader)\n",
        "\n",
        "    return vloss, vacc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMd_XxPku5qp"
      },
      "source": [
        "# Weights and Biases Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjIbhR1wwbgI"
      },
      "source": [
        "This section is to enable logging metrics and files with Weights and Biases. Please refer to wandb documentationa and recitation 0 that covers the use of weights and biases for logging, hyperparameter tuning and monitoring your runs for your homeworks. Using this tool makes it very easy to show results when submitting your code and models for homeworks, and also extremely useful for study groups to organize and run ablations under a single team in wandb.\n",
        "\n",
        "We have written code for you to make use of it out of the box, so that you start using wandb for all your HWs from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCDYx5VEu6qI",
        "outputId": "2ed017c7-a7f4-47bd-e4b1-54dfb81586f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaayush\u001b[0m (\u001b[33maaayush-carnegie-mellon-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "wandb.login(key=\"7664f3b17a98ffe7c64b549e349123b61a9d3024\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "xvUnYd3Bw2up",
        "outputId": "dd93de3c-2e22-4886-ca31-2a95ecfebbec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240912_142144-auxsi0j1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw1p2/runs/auxsi0j1' target=\"_blank\">sixteenth-run</a></strong> to <a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw1p2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw1p2' target=\"_blank\">https://wandb.ai/aaayush-carnegie-mellon-university/hw1p2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw1p2/runs/auxsi0j1' target=\"_blank\">https://wandb.ai/aaayush-carnegie-mellon-university/hw1p2/runs/auxsi0j1</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create your wandb run\n",
        "run = wandb.init(\n",
        "    name    = \"sixteenth-run\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "    reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    #id     = \"y28t31uz\", ### Insert specific run id here if you want to resume a previous run\n",
        "    #resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw1p2\", ### Project should be created in your wandb account\n",
        "    config  = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wft15E_IxYFi",
        "outputId": "0d3f6155-4693-48bc-88a7-fa706130e1a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20240912_142144-auxsi0j1/files/model_arch.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "### Save your model architecture as a string with str(model)\n",
        "model_arch  = str(model)\n",
        "\n",
        "### Save it in a txt file\n",
        "arch_file   = open(\"model_arch.txt\", \"w\")\n",
        "file_write  = arch_file.write(model_arch)\n",
        "arch_file.close()\n",
        "\n",
        "### log it in your wandb run with wandb.save()\n",
        "wandb.save('model_arch.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nclx_04fu7Dd"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdLMWfEpyGOB"
      },
      "source": [
        "Now, it is time to finally run your ablations! Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "6ddc43781cad4074a43472bad551e280",
            "b194de9e5b164394a01651ba87cbe451",
            "809ff104313948ddbe41048dac2a9854",
            "f43bf748e0b740858d5cc8a56edc9e77",
            "6506cdfa78094711abaf8007a31c31d5",
            "cd63e29f8db646c1bb06d74b4208633a",
            "5641b2868300496eb72701cee79e13c5",
            "372fdc08788d4122ba5302e142b88d6c",
            "d82d01d29e114c74a1531df105e9097d",
            "5f5855e2055a4edea3c2bacd6587e7b8",
            "fb4abc567497447782510cf28501c4a7",
            "dab85335ab7340ccab69585a42f711f2",
            "656ce1573f8e494bbf048c0e47ed9246",
            "f95baaec33ae43f7a83902b489a55998",
            "08b54d4b5d654dc6a41a3379de0c394f",
            "c1a91af6951d402395b30d51cb8415a3",
            "d9d9506f4c8d4be99deaf15fa46fdbb1",
            "0f1e2a83a21e41d19a3e577868ca2d49",
            "d23ae2aba6f14acd8006782e73deffad",
            "57488caf5f664a3990b55d5b2851679b",
            "24a195e0ac2a4f1f9440134096683f9f",
            "f287dc5d3bd84c619ff7b287bd4d43a8",
            "6920edfd36f24832be515c94021e3b43",
            "68820cc853ec4658932ba0f3fc186581",
            "ef3ae71aa04045c9aee5994878d1bd69",
            "035edc93a52245809e77824c311ae338",
            "e43ee5d6aec6453889a0e74f54261656",
            "8780a1d7cc8f46c8bfa8393b190be8bc",
            "5856a4a21b6547d187598fc990f03dc4",
            "2cd9dbef514f4fde8acbffc04ae98014",
            "3d062528ddf64905a691046fa8bc1fc8",
            "959267311b70401aa28f2f4c0bcb26a2",
            "6c7d1bc0632b4e9588a11ae57acaadea"
          ]
        },
        "id": "MG4F77Nm0Am9",
        "outputId": "8d5c55c0-ebe3-43dd-c649-9be253317290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/104\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ddc43781cad4074a43472bad551e280"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dab85335ab7340ccab69585a42f711f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Acc 72.3760%\tTrain Loss 0.8566\t Learning Rate 0.0010000\n",
            "\tVal Acc 79.6073%\tVal Loss 0.6109\n",
            "\n",
            "Epoch 2/104\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6920edfd36f24832be515c94021e3b43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "# Iterate over number of epochs to train and evaluate your model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "base_lr = config['init_lr']\n",
        "decay_factor = config['decay_factor']\n",
        "epochs = config['epochs']\n",
        "first_restart = 6\n",
        "second_restart = 12\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr                 = float(optimizer.param_groups[0]['lr'])\n",
        "    train_loss, train_acc   = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc       = eval(model, val_loader)\n",
        "\n",
        "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss, curr_lr))\n",
        "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100, val_loss))\n",
        "\n",
        "\n",
        "    ### Log metrics at each epoch in your run\n",
        "    # Optionally, you can log at each batch inside train/eval functions\n",
        "    # (explore wandb documentation/wandb recitation)\n",
        "    wandb.log({\n",
        "        'train_acc': train_acc * 100,\n",
        "        'train_loss': train_loss,\n",
        "        'val_acc': val_acc * 100,\n",
        "        'valid_loss': val_loss,\n",
        "        'lr': curr_lr,\n",
        "    })\n",
        "\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "    ### Highly Recommended: Save checkpoint in drive and/or wandb if accuracy is better than your current best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZANGzCPD5I8D",
        "outputId": "9435449c-c4d2-4ac4-8c26-8584126e4d5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20240912_142144-auxsi0j1/files/checkpoints/model_epoch_16_1.pt']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "model_save_path = os.path.join(checkpoint_dir, \"model_epoch_16_1.pt\")\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "wandb.save(model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXwf5YUo_4A"
      },
      "source": [
        "# Testing and submission to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI1hSFYLpJvH"
      },
      "source": [
        "Before we get to the following code, make sure to see the format of submission given in *sample_submission.csv*. Once you have done so, it is time to fill the following function to complete your inference on test data. Refer the eval function from previous cells to get an idea of how to go about completing this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DXIO5GlIUkB",
        "outputId": "e5aabe70-9cc4-4d47-c5ff-71b2afb0e19c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# model_save_path = os.path.join(\"checkpoints\", \"model_epoch_15_1.pt\")\n",
        "\n",
        "# model.load_state_dict(torch.load(model_save_path, map_location=torch.device('cuda')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "R-SU9fZ3xHtk"
      },
      "outputs": [],
      "source": [
        "int_to_phoneme = {i: phoneme for phoneme, i in train_data.phoneme_to_int.items()}\n",
        "\n",
        "def test(model, test_loader):\n",
        "    ### What you call for model to perform inference?\n",
        "    model.eval()# TODO train or eval?\n",
        "\n",
        "    ### List to store predicted phonemes of test data\n",
        "    test_predictions = []\n",
        "\n",
        "    ### Which mode do you need to avoid gradients?\n",
        "    with torch.no_grad(): # TODO\n",
        "\n",
        "        for i, mfccs in enumerate(tqdm(test_loader)):\n",
        "\n",
        "            mfccs   = mfccs.to(device)\n",
        "\n",
        "            logits  = model(mfccs)\n",
        "\n",
        "            predicted_phoneme_ids = torch.argmax(logits, dim=1)\n",
        "\n",
        "            predicted_phonemes = [int_to_phoneme[id.item()] for id in predicted_phoneme_ids]\n",
        "\n",
        "            test_predictions.extend(predicted_phonemes)\n",
        "\n",
        "    return test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f17ea41037644ac9b6784e2f25786cc4",
            "b99329bd120747b9a1a35db6cae6ca3a",
            "509aac4b29ee4617aa789dbe3215e495",
            "1f4edd1eb1044c508de3b9e737084733",
            "55632d200ee548faa0be35d0a50f555d",
            "dc4ac8c1a2ce4ffb9e9e4f13c8fdada1",
            "bec1a8a0a10149ff9284388ac5d95839",
            "c69004fca49f45b1a6891dc3ebb4013a",
            "c85fd0a3a483470ca87d78ade2ec152b",
            "72ea672107c64ae59b77deab680cc2fe",
            "26d6531c46ce46779fd094588b2d7b39"
          ]
        },
        "id": "wG9v6Xmxu7wp",
        "outputId": "f94e9c2d-73b2-4ab7-9378-cf9bee2e1c17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/945 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f17ea41037644ac9b6784e2f25786cc4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "predictions = test(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZE1hRnvf0bFz"
      },
      "outputs": [],
      "source": [
        "### Create CSV file with predictions\n",
        "with open(\"./submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wf-P25TXU0N"
      },
      "outputs": [],
      "source": [
        "### Finish your wandb run\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjcammuCxMKN",
        "outputId": "82dcbb62-94f8-422f-aa9f-e9be1b312bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.5.8)\n",
            "100% 19.3M/19.3M [00:01<00:00, 18.6MB/s]\n",
            "Successfully submitted to 11785 HW1P2 Fall 2024"
          ]
        }
      ],
      "source": [
        "### Submit to kaggle competition using kaggle API (Uncomment below to use)\n",
        "!kaggle competitions submit -c 11785-hw1p2-f24 -f ./submission.csv -m \"Test Submission\"\n",
        "\n",
        "### However, its always safer to download the csv file and then upload to kaggle"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ddc43781cad4074a43472bad551e280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b194de9e5b164394a01651ba87cbe451",
              "IPY_MODEL_809ff104313948ddbe41048dac2a9854",
              "IPY_MODEL_f43bf748e0b740858d5cc8a56edc9e77"
            ],
            "layout": "IPY_MODEL_6506cdfa78094711abaf8007a31c31d5"
          }
        },
        "b194de9e5b164394a01651ba87cbe451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd63e29f8db646c1bb06d74b4208633a",
            "placeholder": "​",
            "style": "IPY_MODEL_5641b2868300496eb72701cee79e13c5",
            "value": "Train: 100%"
          }
        },
        "809ff104313948ddbe41048dac2a9854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372fdc08788d4122ba5302e142b88d6c",
            "max": 17623,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d82d01d29e114c74a1531df105e9097d",
            "value": 17623
          }
        },
        "f43bf748e0b740858d5cc8a56edc9e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5855e2055a4edea3c2bacd6587e7b8",
            "placeholder": "​",
            "style": "IPY_MODEL_fb4abc567497447782510cf28501c4a7",
            "value": " 17623/17623 [07:27&lt;00:00,  4.49it/s, acc=72.3760%, loss=0.8566]"
          }
        },
        "6506cdfa78094711abaf8007a31c31d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "cd63e29f8db646c1bb06d74b4208633a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5641b2868300496eb72701cee79e13c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "372fdc08788d4122ba5302e142b88d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82d01d29e114c74a1531df105e9097d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f5855e2055a4edea3c2bacd6587e7b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4abc567497447782510cf28501c4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab85335ab7340ccab69585a42f711f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_656ce1573f8e494bbf048c0e47ed9246",
              "IPY_MODEL_f95baaec33ae43f7a83902b489a55998",
              "IPY_MODEL_08b54d4b5d654dc6a41a3379de0c394f"
            ],
            "layout": "IPY_MODEL_c1a91af6951d402395b30d51cb8415a3"
          }
        },
        "656ce1573f8e494bbf048c0e47ed9246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d9506f4c8d4be99deaf15fa46fdbb1",
            "placeholder": "​",
            "style": "IPY_MODEL_0f1e2a83a21e41d19a3e577868ca2d49",
            "value": "Val: 100%"
          }
        },
        "f95baaec33ae43f7a83902b489a55998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23ae2aba6f14acd8006782e73deffad",
            "max": 942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57488caf5f664a3990b55d5b2851679b",
            "value": 942
          }
        },
        "08b54d4b5d654dc6a41a3379de0c394f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a195e0ac2a4f1f9440134096683f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_f287dc5d3bd84c619ff7b287bd4d43a8",
            "value": " 942/942 [00:36&lt;00:00, 29.09it/s, acc=79.6073%, loss=0.6109]"
          }
        },
        "c1a91af6951d402395b30d51cb8415a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "d9d9506f4c8d4be99deaf15fa46fdbb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1e2a83a21e41d19a3e577868ca2d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d23ae2aba6f14acd8006782e73deffad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57488caf5f664a3990b55d5b2851679b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24a195e0ac2a4f1f9440134096683f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f287dc5d3bd84c619ff7b287bd4d43a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6920edfd36f24832be515c94021e3b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68820cc853ec4658932ba0f3fc186581",
              "IPY_MODEL_ef3ae71aa04045c9aee5994878d1bd69",
              "IPY_MODEL_035edc93a52245809e77824c311ae338"
            ],
            "layout": "IPY_MODEL_e43ee5d6aec6453889a0e74f54261656"
          }
        },
        "68820cc853ec4658932ba0f3fc186581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8780a1d7cc8f46c8bfa8393b190be8bc",
            "placeholder": "​",
            "style": "IPY_MODEL_5856a4a21b6547d187598fc990f03dc4",
            "value": "Train:  64%"
          }
        },
        "ef3ae71aa04045c9aee5994878d1bd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd9dbef514f4fde8acbffc04ae98014",
            "max": 17623,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d062528ddf64905a691046fa8bc1fc8",
            "value": 11220
          }
        },
        "035edc93a52245809e77824c311ae338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959267311b70401aa28f2f4c0bcb26a2",
            "placeholder": "​",
            "style": "IPY_MODEL_6c7d1bc0632b4e9588a11ae57acaadea",
            "value": " 11220/17623 [04:50&lt;02:57, 36.14it/s, acc=78.4969%, loss=0.6498]"
          }
        },
        "e43ee5d6aec6453889a0e74f54261656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8780a1d7cc8f46c8bfa8393b190be8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5856a4a21b6547d187598fc990f03dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cd9dbef514f4fde8acbffc04ae98014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d062528ddf64905a691046fa8bc1fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "959267311b70401aa28f2f4c0bcb26a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7d1bc0632b4e9588a11ae57acaadea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f17ea41037644ac9b6784e2f25786cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b99329bd120747b9a1a35db6cae6ca3a",
              "IPY_MODEL_509aac4b29ee4617aa789dbe3215e495",
              "IPY_MODEL_1f4edd1eb1044c508de3b9e737084733"
            ],
            "layout": "IPY_MODEL_55632d200ee548faa0be35d0a50f555d"
          }
        },
        "b99329bd120747b9a1a35db6cae6ca3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc4ac8c1a2ce4ffb9e9e4f13c8fdada1",
            "placeholder": "​",
            "style": "IPY_MODEL_bec1a8a0a10149ff9284388ac5d95839",
            "value": "100%"
          }
        },
        "509aac4b29ee4617aa789dbe3215e495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69004fca49f45b1a6891dc3ebb4013a",
            "max": 945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c85fd0a3a483470ca87d78ade2ec152b",
            "value": 945
          }
        },
        "1f4edd1eb1044c508de3b9e737084733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ea672107c64ae59b77deab680cc2fe",
            "placeholder": "​",
            "style": "IPY_MODEL_26d6531c46ce46779fd094588b2d7b39",
            "value": " 945/945 [00:32&lt;00:00, 29.85it/s]"
          }
        },
        "55632d200ee548faa0be35d0a50f555d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4ac8c1a2ce4ffb9e9e4f13c8fdada1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec1a8a0a10149ff9284388ac5d95839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69004fca49f45b1a6891dc3ebb4013a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85fd0a3a483470ca87d78ade2ec152b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72ea672107c64ae59b77deab680cc2fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d6531c46ce46779fd094588b2d7b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}